{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vi prøver igen ...\n",
    "\n",
    "![title](FEDentry.GIF)\n",
    "![title](FEDentry2.GIF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'FEDData.xlsx',\n",
       " 'FEDData_All_texts.xlsx',\n",
       " 'FEDData_test.xlsx',\n",
       " 'FEDData_train.xlsx',\n",
       " 'FEDentry.GIF',\n",
       " 'FEDentry2.GIF',\n",
       " 'FED_01_FirstModel.ipynb',\n",
       " 'FED_02_SplitTrainOgTest.ipynb']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vi sætter stien til data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir('/Users/ThomasGordon/Documents/PythonScripts/FED')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Først laver vi en \"dictionary\", som omsætter ord til tal. Den bruges efterfølgende til at omsætte train data og test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThomasGordon\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# filen med tekster åbnes og indlæses\n",
    "file = 'FEDData_All_texts.xlsx'\n",
    "xl = pd.ExcelFile(file)\n",
    "df = xl.parse('RaaData_Forespørgsel')\n",
    "\n",
    "# strenge læses over i en tabel\n",
    "texts  = df.loc[:,'FEDtext']\n",
    "texts  = texts.values\n",
    "\n",
    "# henter text processing modul\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 10000  # Vi ser kun på de 10.000 mest almindelige ord\n",
    "\n",
    "# vi laver ordene i FED om til tilsvarende tal (som igen kan laves til en \"one-hot)\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en funktion som lave en one-hot vektorer\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # lave en all-zero matrix af formen (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Træningsdata indlæses (tekster og labels), først tekst-strengene\n",
    "file = 'FEDData_train.xlsx'\n",
    "xl = pd.ExcelFile(file)\n",
    "df = xl.parse('RaaData_Forespørgsel')\n",
    "texts  = df.loc[:,'FEDtext']\n",
    "labels = df.loc[:,'FEDsize']\n",
    "texts  = texts.values\n",
    "labels = labels.values\n",
    "\n",
    "# ord laves til og der \"paddes\"\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences)\n",
    "\n",
    "# One-hot training data\n",
    "data = vectorize_sequences(data, dimension=max_words)\n",
    "\n",
    "# labels laves til vektor\n",
    "labels = np.asarray(labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19961, 10000)\n",
      "(19961,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15968 samples, validate on 3993 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, labels,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accu = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "#epochs = range(1, len(history_dict['binary_accuracy']) + 1)\n",
    "epochs = range(1, 21)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validering af modellen på test data\n",
    "Her indlæser vi så test data, helt nye data til test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Træningsdata indlæses (tekster og labels), først tekst-strengene\n",
    "file = 'FEDData_test.xlsx'\n",
    "xl = pd.ExcelFile(file)\n",
    "df = xl.parse('RaaData_Forespørgsel')\n",
    "texts_test  = df.loc[:,'FEDtext']\n",
    "labels_test = df.loc[:,'FEDsize']\n",
    "FEDid_test  = df.loc[:,'FEDid']\n",
    "texts_test  = texts_test.values\n",
    "labels_test = labels_test.values\n",
    "FEDid_test  = FEDid_test.values\n",
    "\n",
    "# ord laves til og der \"paddes\"\n",
    "sequences_test = tokenizer.texts_to_sequences(texts_test)\n",
    "data_test = pad_sequences(sequences_test)\n",
    "\n",
    "# One-hot training data\n",
    "data_test = vectorize_sequences(data_test, dimension=max_words)\n",
    "\n",
    "# labels laves til vektor\n",
    "labels_test = np.asarray(labels_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi prøver modellen på test-data\n",
    "predictions = model.predict(data_test)\n",
    "\n",
    "# vi printer min, max og nogle eksempler\n",
    "print(min(predictions), max(predictions))\n",
    "SplitVal = (min(predictions) + max(predictions))/2\n",
    "print(predictions[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Antal store i datasættet:    ', sum(labels_test))\n",
    "\n",
    "NumEstimated = 0\n",
    "for i in range(1,6000):\n",
    "    if predictions[i]>0.01 and FEDid_test[i]<=493:\n",
    "        NumEstimated += 1\n",
    "print('antal estimeret af modellen: ', NumEstimated)\n",
    "\n",
    "print('Modellens præcision:         ', round(NumEstimated/sum(labels_test)*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6000):\n",
    "    if labels_test[i]==1:\n",
    "        print(i+2, predictions[i], texts_test[i])    # i+2 er linjen i regnearket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('before: {:.2f} after'.format(1.5555))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
